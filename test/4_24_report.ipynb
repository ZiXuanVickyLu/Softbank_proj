{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cow parameter model\n",
    "We use SMAL (Skinned Multi-Animal Linear model) as the raw parameter models.\n",
    "![](../data/smal.png)\n",
    "### Task\n",
    "Input: Video/mutiple-view image\n",
    "Output: Cow model\n",
    "\n",
    "pipeline: Video/multiple-view image -> registed smal raw model -> Differential-based retargeting -> fine model with shape\n",
    "\n",
    "### SMAL Training\n",
    "A Global/Local Stitched Shape Model. SMAL use a segmentational template where body shape deformations are locally defined and reducing the loss of stitching cost at interface.  \n",
    "![](../data/segmentation.png)\n",
    "\n",
    "### Model\n",
    "The SMAL model is a function $M(\\beta, \\theta, \\gamma)$ of shape $\\beta$, pose $\\theta$ and translation $\\gamma$. \n",
    " - $\\beta$ is the PCA shape space\n",
    " - $\\theta\\in \\mathbb R^{3N}$, where $N=33$ is the relative rotation of 33 joints in the kinematic tree\n",
    " - $\\gamma$ is the global translation applied to the root joint \n",
    " - Input: $\\beta,\\theta,\\gamma$\n",
    " - Output: $M(\\beta,\\theta,\\gamma)$ is a 3D model.\n",
    "- To be specific: $M(\\beta,\\theta,\\gamma)=\\text{LBS}\\left(\\Theta(\\theta,\\gamma),\\overline{T}(\\beta)\\right)$\n",
    "  - LBS is linear blend shape model, taking the template and pose\n",
    "  - $\\overline{T}(\\beta)$ is the template of registered pose taking the shape vector $\\beta$\n",
    "  - $\\Theta$ is the per-joint transform taking the relative pose vector $\\theta$ from kinematic tree and a global tranformation $\\gamma$ to the root joint.\n",
    "  \n",
    "## Demo\n",
    "\n",
    "## Next step\n",
    "### Fitting the model to image\n",
    "Fitting the SMAL model, $M(\\beta,\\theta,\\gamma)$, to image cues by optimizing the shape and pose parameters.\n",
    " - Segmentation and keypoint extraction\n",
    "  - ![](../data/keypoint.png)\n",
    " - As we denote $\\prod(\\cdot;f)$ as the perspective camera projection with focal length $f$ , where $\\prod(v_i;f)$ is the projection of the i’th vertex onto the image plane (asume the camera is zero rotated and placed on the original point).\n",
    " - Using differentiable rendering technique to fitting the SMAL model by keypoint\n",
    " - Loss (each term has a hyper-parameter): \n",
    "  $$E(\\text{SMAL},\\mathbf x)=E_{kp}(\\text{SMAL},\\mathbf x) + E_\\beta(\\beta) + E_\\theta(\\theta)$$\n",
    "as the keypoint from the render given the loss:\n",
    " $$E_{kp}(\\text{SMAL},\\mathbf x)= \\sum_k\\rho\\left(||\\mathbf x\\frac{1}{k_m}\\sum_{j-1}|k_m|\\prod(\\mathbf v_{k_j};\\text{SMAL})||_2\\right)$$ \n",
    " where $\\rho$ is Geman-McClure Error Function (stable to outlier), \n",
    " and $E(\\beta) =||\\beta - \\beta_0||_2$ and $E(\\theta) = ||\\theta - \\theta_0||_2$ is the regularization variational term to guide the model to a user defined prior parameter.\n",
    "\n",
    " Then we can use a differentialble render to optimized the model parameter to reduce the loss.\n",
    "  \n",
    "\n",
    "### Retargeting\n",
    "#### Point cloud registering\n",
    "Problem Definition:\n",
    "\n",
    "Given two point clouds:\n",
    " - Source point cloud $S = \\{s_1, ..., s_n\\}$\n",
    " - Target point cloud $T = \\{t_1, ..., t_m\\}$.\n",
    "  \n",
    "The goal is to find the optimal rigid transformation (rotation $R$ and translation $t$) that aligns the source point cloud with the target point cloud.\n",
    "\n",
    "**Transformation Model**\n",
    "\n",
    "The rigid transformation is defined as:\n",
    "$s'_i = Rs_i + t$ where $R$ is a 3×3 rotation matrix,\n",
    "$t$ is a 3×1 translation vector,\n",
    "$s_i$ is a point in the source cloud,\n",
    "$s'_i$ is the transformed point.\n",
    "\n",
    "We uses the SO(3) exponential map to parameterize rotation:\n",
    "$R = \\exp(\\omega^\\wedge)$ where:\n",
    "$\\omega$ is a 3D rotation vector,\n",
    "$\\exp$ is the matrix exponential,\n",
    "$^\\wedge$ converts a 3D vector to a 3×3 skew-symmetric matrix.\n",
    "\n",
    "**Chamfer Distance as loss function**\n",
    "\n",
    "The algorithm uses Chamfer Distance as the loss function:\n",
    "$$L(S, T) = \\frac{1}{|S|}\\sum_{s \\in S}\\min_{t \\in T}||s - t||^2 + \\frac{1}{|T|}\\sum_{t \\in T}\\min_{s \\in S}||s - t||^2$$\n",
    "\n",
    "We aimed to use point registering algorithm to achieve the retargeting.\n",
    " - Motivation: input ($\\beta$,$\\Theta$), output: fine mesh\n",
    " - The backward gradient to reduce the loss:\n",
    "$$\\frac{\\partial{\\text{chamfer\\_distance}}}{\\partial \\{\\beta,\\Theta\\}}=\\frac{\\partial \\text{chamfer\\_distance}}{\\partial \\text{fine\\_mesh}}\\cdot\\frac{\\partial \\text{fine\\_mesh}}{\\partial \\text{SMAL\\_model}}\\cdot\\frac{\\partial \\text{SMAL\\_model}}{\\partial \\{\\beta,\\Theta\\}}$$\n",
    " - The fitting step will output the $\\{\\beta,\\Theta\\}$, we can then use the gradient from SMAL and the interpolation matrix between SMAL raw mesh and the fine mesh($\\frac{\\partial \\text{fine\\_mesh}}{\\partial \\text{SMAL\\_model}}$) from the same pose as well as the gradient from point cloud registering ($\\frac{\\partial \\text{chamfer\\_distance}}{\\partial \\text{fine\\_mesh}}$) to obtain the retargeted fine mesh.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
